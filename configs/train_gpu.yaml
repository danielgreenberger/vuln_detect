# GPU-optimized training configuration for vulnerability detection
# This configuration maximizes GPU utilization with larger batch sizes and mixed precision

# Data configuration
data:
  data_path: "data/Suicide_Detection.csv"
  max_length: 512
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  random_seed: 42
  balance_strategy: null  # Options: null, "undersample", "oversample"
  text_column: "text"
  label_column: "label"

# Model configuration
model:
  model_name: "cardiffnlp/twitter-roberta-base"
  num_labels: 3
  use_gradient_checkpointing: true  # Save memory for larger batches
  dropout: 0.1

# Training configuration
training:
  output_dir: "outputs/gpu_run"
  num_epochs: 3
  batch_size: 32  # Larger batch size for GPU
  learning_rate: 3.0e-5
  weight_decay: 0.01
  warmup_steps: 500
  eval_steps: 250  # More frequent evaluation
  save_steps: 500
  logging_steps: 50
  gradient_accumulation_steps: 1
  fp16: true  # Enable mixed precision training
  device: "cuda"  # Explicitly use CUDA
  report_to: "none"  # Disable TensorBoard (change to "tensorboard" to enable)